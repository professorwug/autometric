# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/3b7 PHATE Embedding Experiments.ipynb.

# %% auto 0
__all__ = ['device', 'run_PHATE_embedding_experiment', 'plot_PHATE_embedding_experiment']

# %% ../nbs/3b7 PHATE Embedding Experiments.ipynb 0
import numpy as np
import matplotlib.pyplot as plt

# datasets
from diffusion_curvature.datasets import sphere, torus
from sympy import im
from .n0d2_datasets import make_swiss_roll, generate_sine_wave_dataset
from .n0u1_visualization import plot_jacobian, plot_jacobian_multi
from .n0u2_jacobian import compute_jacobian_function

import os
os.environ["GEOMSTATS_BACKEND"] = "pytorch"

# models
import torch
from .autoencoders import DerrickTheAutoencoder
from diffusion_curvature.utils import plot_3d


device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
# 
import matplotlib.style as style
style.use('seaborn-poster') #sets the size of the charts
style.use('ggplot')
import plotly.express as px


import phate
from phate.mds import embed_MDS
from .geometry import visualize_encoder_pullback_metrics
from .geometry import visualize_encoder_pullback_metrics_in_ambient_space
from .autoencoders import FlexibleDMAutoencoder
# from autometric.autoencoders import CoordinatewiseDistanceMatchingAutoencoder
# from autometric.datasets import train_and_testloader_from_pointcloud_with_distances
# from autometric.datasets import train_and_testloader_from_pointcloud_phate_coords
from .datasets import train_and_testloader_from_flexpc
from pytorch_lightning import Trainer
from pytorch_lightning.callbacks import EarlyStopping

import pathlib

# %load_ext autoreload
# %autoreload 2

# %% ../nbs/3b7 PHATE Embedding Experiments.ipynb 1
def run_PHATE_embedding_experiment(
        datasetname,
        phate_decay = 40,
        n_neighbors = 15,
        phate_gamma = 1,
        phate_knn = 15,
        distance_weight = 1,
        reconstruction_weight = 1,
        coordinatewise=False,
        include_pretraining=False,
        savepath = '../data',
        max_epochs = 50,
        plot=False
    ):
    pathlib.Path(savepath).mkdir(parents=True, exist_ok=True)



    if os.path.exists(f"{savepath}/{datasetname}.npy"):
        X = np.load(f"{savepath}/{datasetname}.npy")
        print("Loaded dataset from disk")
    else:
        if datasetname == 'swiss_roll':
            Xs, thetas = make_swiss_roll(turns=2, a=0.1, base_delta_theta=0.1 * 2 * np.pi, theta=1.5 * np.pi, noise=0.)
            ambient_noise = np.random.normal(0, 0.05, size=Xs.shape)
            Xs += ambient_noise
        elif datasetname == 'wavy_sheet':
            Xs = generate_sine_wave_dataset(num_points=2000, amplitude=2, frequencies=(1, 1))
            ambient_noise = np.random.normal(0, 0.05, size=Xs.shape)
            Xs += ambient_noise
        elif datasetname == 'sphere':
            Xs, N = sphere(n=2000, noise=0.05)
        elif datasetname == 'torus':
            Xs, N = torus(n=2000, noise=0.05)
        else:
            raise ValueError(f'Unknown dataset name: {datasetname}')
        X = Xs
        np.save(f"{savepath}/{datasetname}.npy", X)

    if os.path.exists(f"{savepath}/phate_{datasetname}_coords.npy") and os.path.exists(f"{savepath}/phate_{datasetname}_D.npy"):
        phate_coords = np.load(f"{savepath}/phate_{datasetname}_coords.npy")
        phate_D = np.load(f"{savepath}/phate_{datasetname}_D.npy")
        print("Loaded PHATE embedding from disk")
    else:
        print(f"Computing PHATE with {phate_decay=} and {n_neighbors=}")
        phate_op = phate.PHATE(gamma=phate_gamma, knn=phate_knn, random_state=42) #n_components = 2, decay=phate_decay, knn=self.n_neighbors
        phate_coords = phate_op.fit_transform(X)
        phate.plot.scatter2d(phate_coords)
        phate_coordst = torch.tensor(phate_coords)
        phate_D = torch.cdist(phate_coordst, phate_coordst).cpu().detach().numpy()
        np.save(f"{savepath}/phate_{datasetname}_coords.npy", phate_coords)
        np.save(f"{savepath}/phate_{datasetname}_D.npy", phate_D)


    # Create dataloaders
    trainloader, testloader = train_and_testloader_from_flexpc(
        X, # <---- Pointcloud
        phate_coords, # <---- MDS coordinates are actually the PHATE coordinates
        phate_coords, # <---- PHATE coordinates
        phate_D, # <---- Distance matrix to match
        batch_size=64)
    train_sample = next(iter(trainloader))

    # Initialize model and trainer
    model = FlexibleDMAutoencoder(
        input_dim = train_sample['x'].shape[1],
        intrinsic_dim = 2,
        )
    early_stopping = EarlyStopping('val_loss', patience=500)
    trainer = Trainer(
        max_epochs=max_epochs, 
        accelerator='cuda',
        callbacks=[early_stopping],
        use_distributed_sampler=False,
        log_every_n_steps=50,
        )
    if include_pretraining:
        pretrainer = Trainer(
        max_epochs=max_epochs, 
        accelerator='cuda',
        callbacks=[early_stopping],
        use_distributed_sampler=False,
        log_every_n_steps=50,
        )
        model.set_pretrain(distance_weight=distance_weight, reconstruction_weight=distance_weight)
        pretrainer.fit(
            model=model,
            train_dataloaders=trainloader,
            val_dataloaders=testloader,
        )
        stage = 'pretrain'
        model_filename = f"{datasetname}_{distance_weight}_{reconstruction_weight}_{coordinatewise}_{stage}.pt"
        torch.save(model.state_dict(), f'{savepath}/{model_filename}')
        model.set_finetune(distance_weight=distance_weight, reconstruction_weight=reconstruction_weight, coordinatewise=coordinatewise)
        trainer.fit(
            model=model,
            train_dataloaders=trainloader,
            val_dataloaders=testloader,
        )
        stage = 'finetune'
        model_filename = f"{datasetname}_{distance_weight}_{reconstruction_weight}_{coordinatewise}_{stage}.pt"
        torch.save(model.state_dict(), f'{savepath}/{model_filename}')
        print("saved_{model_filename}")
    else:
        stage = 'train'
        model.set_finetune(distance_weight=distance_weight, reconstruction_weight=reconstruction_weight, coordinatewise=coordinatewise)
        trainer.fit(
            model=model,
            train_dataloaders=trainloader,
            val_dataloaders=testloader,
        )
        model_filename = f"{datasetname}_{distance_weight}_{reconstruction_weight}_{coordinatewise}_{stage}.pt"
        torch.save(model.state_dict(), f'{savepath}/{model_filename}')

def plot_PHATE_embedding_experiment(
        datasetname,
        distance_weight = 1,
        reconstruction_weight = 1,
        coordinatewise=False,
        savepath = '../data',
        stage='train',
        **kwargs
):
    if datasetname == 'swiss_roll':
        scale = 0.2
    elif datasetname == 'wavy_sheet':
        scale = 0.5
    elif datasetname == 'sphere':
        scale = 0.2
    elif datasetname == 'torus':
        scale = 0.5
    else:
        print(f'Unknown dataset name: {datasetname}, using default scale 1')
        scale = 1
    X = np.load(f"{savepath}/{datasetname}.npy")
    phate_coords = np.load(f"{savepath}/phate_{datasetname}_coords.npy")
    phate_D = np.load(f"{savepath}/phate_{datasetname}_D.npy")
    # Create dataloaders
    trainloader, testloader = train_and_testloader_from_flexpc(
        X, # <---- Pointcloud
        phate_coords, # <---- MDS coordinates are actually the PHATE coordinates
        phate_coords, # <---- PHATE coordinates
        phate_D, # <---- Distance matrix to match
        batch_size=64)
    train_sample = next(iter(trainloader))
    model_filename = f"{datasetname}_{distance_weight}_{reconstruction_weight}_{coordinatewise}_{stage}.pt"
    model = FlexibleDMAutoencoder(
        input_dim = train_sample['x'].shape[1],
        intrinsic_dim = 2,
        )
    model.load_state_dict(torch.load(f'{savepath}/{model_filename}'))
    visualize_encoder_pullback_metrics(model, trainloader, title = f"PHATE Embedding of {datasetname}")
    visualize_encoder_pullback_metrics_in_ambient_space(model, trainloader, title = f"PHATE Embedding of {datasetname}")

    X_tensor = torch.from_numpy(X).float()
    jac = compute_jacobian_function(model.encoder, X_tensor)
    U, S, V = torch.linalg.svd(jac, full_matrices=False)
    X_enc = model.encoder(X_tensor)

    js = np.random.choice(X.shape[0], size=100)
    plot_jacobian_multi(X_tensor, X_enc, U, V, S, jac, js, scale1=scale)

    enc = model.encoder(X_tensor)
    ground_truth_distances = torch.from_numpy(phate_D).float()
    phate_coords = torch.from_numpy(phate_coords).float()
    if stage == 'pretrain':
        dist_l = model.pretrain_loss(enc, phate_coords)
    elif coordinatewise:
        dist_l = model.distance_loss_coorw(enc, phate_coords)
    else:
        dist_l = model.distance_loss(enc, ground_truth_distances)
    x_hat = model.decoder(enc)
    from torch import nn
    reconstr_l = nn.MSELoss()(x_hat, X_tensor)
    print(f"Distance loss: {dist_l.item():.3f}, Reconstruction loss: {reconstr_l.item():.3f}")

    x_embedded = enc
    embedding_distances = torch.cdist(x_embedded, x_embedded)
    prepared_embedded = (embedding_distances)        
    prepared_truth = (ground_truth_distances)
    dist_l_new = nn.MSELoss()(prepared_embedded, prepared_truth)
    print(dist_l_new.item())

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))

    ax1.scatter(x_embedded.detach().numpy()[:, 0], x_embedded.detach().numpy()[:, 1], c=phate_coords.detach().numpy()[:, 0])
    ax1.set_xlabel('x_embedded[:,0]')
    ax1.set_ylabel('x_embedded[:,1]')
    ax1.set_title('x_embedded colored by phate_coords[:,0]')

    ax2.scatter(x_embedded.detach().numpy()[:, 0], x_embedded.detach().numpy()[:, 1], c=phate_coords.detach().numpy()[:, 1])
    ax2.set_xlabel('x_embedded[:,0]')
    ax2.set_ylabel('x_embedded[:,1]')
    ax2.set_title('x_embedded colored by phate_coords[:,1]')

    plt.suptitle(f'{datasetname}: Comparison of x_embedded and phate_coords, distance loss: {dist_l.item():.2e}, distance MSE: {dist_l_new.item():.2e}')
    plt.tight_layout()
    plt.show()

