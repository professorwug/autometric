# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/library/branch-datasets.ipynb.

# %% auto 0
__all__ = ['random_polynomial', 'Stick', 'Branch']

# %% ../../nbs/library/branch-datasets.ipynb 3
import sympy as sp
import numpy as np
import itertools

def random_polynomial(
        vars, # variables to construct polynomial from
        degree = 2, # maximum degree of terms
        scale = 1, # scale of the polynomial coefficients (sampled from 0 to 1, multiplied by this)
):
    num_variables = len(vars)
    terms = []
    for d in range(1, degree + 1):
        for indices in itertools.combinations_with_replacement(range(num_variables), d):
            terms.append(np.prod([vars[i] for i in indices]))
    coeffs = np.random.uniform(size = len(terms))*scale
    return sum([coeffs[i] * terms[i] for i in range(len(terms))])


# %% ../../nbs/library/branch-datasets.ipynb 4
from fastcore.all import *
import sympy as sp
import scipy.integrate

class Stick():
    def __init__(
        self,
        dimension,
        degree,
        starting_point,
        time_range = 1
    ):
        store_attr()
        # construct a unique polynomial for yourself
        x = sp.symbols('x')
        self.x = x
        p = random_polynomial(
            [x],degree
        )
        self.polynomial = p
        self.polynomial_np = sp.lambdify([x], self.polynomial, "numpy")
        self.starting_point = starting_point

        # random direction for polynomial, scaled to unit length
        self.direction = np.random.randn(self.dimension)
        self.direction /= np.linalg.norm(self.direction)

    def sample_at_time(self,t):
        return self.polynomial_np(self.direction*t) + self.start_point()

    def end_point(self):
        return self.sample_at_time(self.time_range)
    def start_point(self):
        return self.starting_point

    def sample(self, n_samples):
        ts = np.random.rand(n_samples)*self.time_range
        Xs = [self.sample_at_time(t) for t in ts]
        return np.array(Xs)
    
    # def length(self):
    #     l = -1
    #     i = 0
    #     while l < 0 and i < 100:
    #         l = self._length()
    #         print(l, 'at time', i, 'with polynomial', self.polynomial)
    #         i += 1
    #     return l
        
        
    # def length(self):
    #     # integrate the polynomial over the time range
    #     # using sympy
    #     x = sp.symbols('x')
    #     # path length integrand
    #     integrand = sp.sqrt(1 + sp.diff(self.polynomial, x)**2)
    #     integral = integrand.integrate()
        
    #     integral = sp.N(sp.integrate(
    #         integrand, (x, 0, self.time_range), 
    #         ))
    #     integral_fn = sp.lambdify([x], integral, "numpy")
    #     integrated_length = integral_fn(self.time_range)
    #     print('integrated length is',integral, 'numpy version is',integrated_length)
    #     return integrated_length
    
    def length(self):
        # Using these numerical methods is SO much faster than using sympy
        df_dx = sp.diff(self.polynomial, self.x)
        f_prime = sp.lambdify(self.x, df_dx, 'numpy')

        # Step 4: Define the function to integrate to find the curve length
        def integrand(x):
            return np.sqrt(1 + f_prime(x)**2)

        # Step 5: Calculate the curve length over a specified interval, e.g., from x = 0 to x = 1
        a, b = 0, self.time_range
        curve_length, _ = scipy.integrate.quad(integrand, a, b)

        return curve_length

# %% ../../nbs/library/branch-datasets.ipynb 7
import random
import numpy as np
import torch
import networkx as nx

class Branch():
    def __init__(
        self,
        dimension,
        polynomial_degree=2,
        max_branches=3,
        path_length = 5,
        num_samples = 2000,
        seed = None,
    ):
        store_attr()
        if seed is not None:
            torch.manual_seed(seed)
            np.random.seed(seed)
            random.seed(seed)

        self.sticks = [
            Stick(
                dimension,
                polynomial_degree,
                np.zeros(dimension)
            )
        ]
        self.branching_nums = [np.random.randint(2,max_branches)]
        
        
        # create a networkx graph
        self.G = nx.Graph()
        # add the first stick
        self.G.add_node(0)

        stick_idx = 0
        for i in range(path_length):
            # go through all sticks after stick_idx and create new sticks at their ends
            new_stick_idx =len(self.sticks)
            for j in range(stick_idx,len(self.sticks)):
                num_new_sticks = self.branching_nums[j]
                for k in range(num_new_sticks):
                    # create a stick
                    stick = Stick(
                        dimension,
                        polynomial_degree,
                        self.sticks[j].end_point(),
                    )
                    self.sticks.append(stick)
                    self.branching_nums.append(
                        np.random.randint(2,max_branches)
                    )
                    # add a node to the graph
                    self.G.add_node(len(self.sticks)-1)
                    # add an edge between the idx of the previous stick and the idx of the new stick
                    # j is the previous stick, since this is the end point; len(self.sticks)-1 is the new stick since it's the last stick
                    self.G.add_edge(j, len(self.sticks)-1)
                    
            stick_idx = new_stick_idx
        self.branching_nums = np.array(self.branching_nums)
        self.X = self.sample(num_samples)
        self.X_ground_truth = self.X

    def sample(self,n_samples=5000):
        self.num_branches_per_point = []
        self.branch_lengths = []
        self.samples_to_sticks = []
        
        Xs = []
        samples_per_stick = n_samples // len(self.sticks)
        for i, stick in enumerate(self.sticks):
            Xs.append(np.vstack([stick.sample(samples_per_stick-1),stick.end_point()]))
            self.num_branches_per_point.append(np.append(np.zeros(n_samples-1), self.branching_nums[i]))
            self.branch_lengths.append(
                np.ones(samples_per_stick)*stick.length()
            )
            self.samples_to_sticks.append(np.ones(samples_per_stick)*i)
        self.num_branches_per_point = np.concatenate(self.num_branches_per_point)
        self.branch_lengths = np.concatenate(self.branch_lengths)
        self.samples_to_sticks = np.concatenate(self.samples_to_sticks)
        return np.concatenate(Xs,axis=0)
    
    def pairwise_geodesic(self, a:np.ndarray, b:np.ndarray, ts):
        # check that both a and b are in self.X
        # find the distance between each point in self.X and a and then b
        dists_to_a = np.linalg.norm(self.X - a, axis=1)
        dist, idx_a = np.min(dists_to_a, axis=0), np.argmin(dists_to_a, axis=0)
        assert dist < 1e-3, f"Not sampled point. Distance between {a} and {self.X[idx_a]} is {dist}"
        dists_to_b = np.linalg.norm(self.X - b, axis=1)
        dist, idx_b = np.min(dists_to_b, axis=0), np.argmin(dists_to_b, axis=0)
        assert dist < 1e-3, f"Not sampled point. Distance between {b} and {self.X[-dx_b]} is {dist}"
        
        a_stick_idx = self.samples_to_sticks[idx_a]
        b_stick_idx = self.samples_to_sticks[idx_b]
        
        # get a djikstra path from a_stick_idx to b_stick_idx with self.G
        path = nx.shortest_path(self.G, a_stick_idx, b_stick_idx)
        path = list(path)# a list of stick idxs.
        path = [int(p) for p in path]
        if len(path) == 1:
            # both points are on the same stick. We approximate the geodesic as the stick. # TODO: restrict stick length to be less than the distance between the two points
            length = self.sticks[path[0]].length()
            return self.sticks[path[0]].sample(len(ts)), length
        
        # get distance from a to the closest endpoint of the path - closest to the next stick, that is. 
        # this is the same as the distance from a to the starting point of the next stick.
        starting_dist = np.linalg.norm(
            self.sticks[path[1]].start_point() - a
        )
        ending_dist = np.linalg.norm(
            self.sticks[path[-2]].end_point() - b
        )
        intermediate_dists = [self.sticks[p].length() for p in path[1:-1]]
        length = starting_dist + np.sum(intermediate_dists) + ending_dist
        
        # get the points along the path. We'll just sample new points along each of the intermediate sticks. 
        # For the starting and ending stick, we'll sample points and reject those which are further from the nearest stick than a and b respectively.
        def num_samples_per_length(partial_length):
            l =  int((partial_length / length) * len(ts))
            if l == 0: l = 1
            return l
        def num_points_so_far(points):
            return sum([len(p) for p in points])

        points = []
        starting_samples = self.sticks[path[0]].sample(num_samples_per_length(starting_dist))
        # reject points which are further from the next stick than a
        starting_samples = starting_samples[np.linalg.norm(starting_samples - self.sticks[path[1]].start_point(), axis=1) <= starting_dist]
        points.append(starting_samples)
        ending_samples = self.sticks[path[-1]].sample(num_samples_per_length(ending_dist))
        ending_samples = ending_samples[np.linalg.norm(ending_samples - self.sticks[path[-2]].end_point(), axis=1) < ending_dist]
        points.append(ending_samples)

        # if there are more than 2 sticks, here we sample intermediate points
        if len(path) > 2:
            for p, partial_length in zip(path[1:-2], intermediate_dists[:-1]):
                # get the points on the stick
                n = num_samples_per_length(partial_length)
                if n < 10: n = 10
                stick_points = self.sticks[p].sample(n)
                points.append(stick_points)
            # for the last intermediate stick, we'll supplement the samples to get the desired length
            num_samples = num_samples_per_length(intermediate_dists[-1]) + (len(ts) - num_samples_per_length(intermediate_dists[-1]) - num_points_so_far(points))
            if num_samples < 2: 
                num_samples = 2
            stick_points = self.sticks[path[-2]].sample(num_samples)
            points.append(stick_points)
        else:
            # to fill in the geodesic to desired length, we'll just repeatedly sample from start and end
            while num_points_so_far(points) < len(ts):
                points_left = (len(ts) - num_points_so_far(points)) // 2 + 1
                starting_samples = self.sticks[path[0]].sample(points_left)
                starting_samples = starting_samples[np.linalg.norm(starting_samples - self.sticks[path[1]].start_point(), axis=1) <= starting_dist]
                points.append(starting_samples)
                ending_samples = self.sticks[path[-1]].sample(points_left)
                ending_samples = ending_samples[np.linalg.norm(ending_samples - self.sticks[path[-2]].end_point(), axis=1) < ending_dist]
                points.append(ending_samples)
        
        # if len(points) exceeds len(ts), randomly subsample
        if num_points_so_far(points) > len(ts):
            points = points[:len(ts)]
        g = np.concatenate(points)
        if len(g) != len(ts):
            raise ValueError(f"Geodesic length is not equal to number of timesteps, with {len(g)} points and {len(ts)} timesteps and {len(path)} path points")
        return g, length
    
    def geodesics(self, start_points, end_points, ts):
        """
        Takes start, endpoint pairs in ambient space, and list of times. Returns geodesics and lengths.
        """
        # test if start and end points are tensors
        if isinstance(start_points, np.ndarray):
            start_points = torch.tensor(start_points)
        if isinstance(end_points, np.ndarray):
            end_points = torch.tensor(end_points)
        if isinstance(ts, np.ndarray):
            ts = torch.tensor(ts)
        
        # test if start and end points are among the previously sampled points
        # for each point, find the closest point in the sampled points. If it exceeds a threshold of 1e-3, then raise an error.
        distances_to_sampled_points = torch.cdist(torch.cat([start_points, end_points], dim=0), torch.tensor(self.X))
        corresponding_idxs = torch.argmin(distances_to_sampled_points, dim=1)
        
        for i in range(len(start_points)):
            # closest_idx = torch.argmin(distances_to_sampled_points[i], dim=0)
            closest_value = distances_to_sampled_points[i][corresponding_idxs[i]]
            if closest_value > 1e-3:
                raise ValueError(f"Start and end points must be among the previously sampled points. Min dist to manifold is {closest_value}")
            
        gs = []
        lengths = []
        for i in range(len(start_points)):
            g, l = self.pairwise_geodesic(start_points[i].numpy(), end_points[i].numpy(), ts)
            gs.append(torch.tensor(g))
            lengths.append(torch.tensor(l))
            
        # make conversion safe
        lengths = torch.tensor(lengths)
        gs = [g.cpu().detach() for g in gs]
        lengths = lengths.cpu().detach()
        return gs, lengths
        
        
        
