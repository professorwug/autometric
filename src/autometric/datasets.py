# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/library/datasets.ipynb.

# %% auto 0
__all__ = ['manifold_density', 'max_value', 'rejection_sample_from_surface', 'generate_rotation_matrix', 'rotate_data_np',
           'rotate_data', 'ToyManifold', 'Torus', 'Saddle', 'Ellipsoid', 'Sphere', 'Hemisphere', 'SwissRoll',
           'PointcloudDataset', 'PointcloudWithDistancesDataset', 'dataloader_from_pointcloud_with_distances',
           'train_and_testloader_from_pointcloud_with_distances', 'plot_3d_vector_field', 'sphere_with_normals',
           'export_datasets', 'GeodesicToyChest']

# %% ../../nbs/library/datasets.ipynb 5
import numpy as np
import scipy.optimize as opt
import sympy as sp
import torch

def manifold_density(f, variables):
    G = sp.Matrix.zeros(len(variables), len(variables))
    for i, x1 in enumerate(variables):
        for j, x2 in enumerate(variables):
            G[i,j] = (sp.diff(f, x1).T  * sp.diff(f, x2))[0]
    return sp.sqrt(G.det(method="lu"))

def max_value(expr, bounds):
    # Convert sympy expression to numpy function
    vars = list(expr.free_symbols)
    expr_neg = -1*expr
    neg_func = sp.lambdify([vars], expr_neg, 'numpy')

    # Minimize negative of function over range [-1, 1]
    bounds = [bounds for _ in vars] # TODO: fails when there are no vars
    res = opt.minimize(neg_func, np.zeros(len(vars)), bounds=bounds)
    
    # Return maximum value
    return -res.fun
def rejection_sample_from_surface(
        F, # a sympy matrix of size $N \times 1$ representing a surface
        n_points, # number of points to sample
        bounds=[-1,1], # bounds for each variable
        batch_size=1024, # number of points to test sampling at a time
        verbose=False,
        return_latent_vars=False,
):
    if verbose: print("Hey, just woke up")
    vars = sorted(F.free_symbols, key=lambda s: s.name)
    f = manifold_density(F, vars)
    g = 1/((bounds[1]-bounds[0])**len(vars)) # uniform density on [-1, 1] for each variable
    M = max_value(f/g, bounds=bounds) # M >= f/g for all x
    if verbose: print("Computed f, M, g")
    bouncer = (f / (M * g)) #.simplify()
    # print(bouncer)
    points = []
    latent_vars = []
    # convert f to numpy
    F_np = sp.lambdify([vars], F, 'numpy')
    bouncer_np = sp.lambdify([vars], bouncer, 'numpy')
    # add the origin as first point

    if verbose: print("Computed bouncer np")
    while len(points) < n_points:
        euc_coords = np.random.uniform(bounds[0], bounds[1], (batch_size,len(vars)))
        x = np.array(list(map(F_np,euc_coords)))
        if verbose: print("computed sample candidates")
        u = np.random.uniform(0, 1, batch_size)
        # print(u)
        # compute mask of points that pass the bouncer
        bouncer_results = np.array(list(map(bouncer_np,euc_coords)))
        if verbose: print("computed bouncer results")
        mask = u < bouncer_results
        points.extend(x[mask])
        latent_vars.extend(euc_coords[mask])
        if verbose:
            print(f"Points added {np.sum(mask)} for a total of {len(points)}")
        # if u < bouncer_np(euc_coords):
        #     points.extend(x)
    if len(points) > n_points:
        points = points[:n_points]
        latent_vars = latent_vars[:n_points]
    if return_latent_vars: 
        return np.squeeze(np.array(points)), np.squeeze(np.array(latent_vars))
    else: 
        return np.squeeze(np.array(points))

# %% ../../nbs/library/datasets.ipynb 6
import torch
# rotation script by xingzhis
def generate_rotation_matrix(n, seed=1):
    """
    Generates a random n-dimensional rotation matrix.
    
    Parameters:
        n (int): The dimension of the rotation matrix to be generated.
    
    Returns:
        np.ndarray: An n x n orthogonal matrix with determinant 1.
    """
    # Start with an identity matrix
    A = np.eye(n)
    np.random.seed(seed)
    for i in range(n):
        for j in range(i+1, n):
            # Generate a random angle
            theta = np.random.uniform(0, 2*np.pi)
            
            # Create the Givens rotation matrix for this angle
            G = np.eye(n)
            cos_theta, sin_theta = np.cos(theta), np.sin(theta)
            G[i, i] = cos_theta
            G[j, j] = cos_theta
            G[i, j] = -sin_theta
            G[j, i] = sin_theta
            
            # Apply the Givens rotation
            A = np.dot(G, A)
    
    # Ensure the matrix is a rotation matrix (det = 1)
    if np.linalg.det(A) < 0:
        A[:, 0] = -A[:, 0]
    
    return A

def rotate_data_np(data, n=100, seed=1, return_rot_mat=False, rotation_matrix=None):
    if rotation_matrix is None:
        rotation_matrix = generate_rotation_matrix(n, seed)
    rotated_data = np.c_[data, np.zeros((data.shape[0],n - data.shape[1]))] @ rotation_matrix
    if return_rot_mat:
        return rotated_data, rotation_matrix
    return rotated_data


def rotate_data(data, n=100, seed=1, return_rot_mat=False, rotation_matrix=None):
    if rotation_matrix is None:
        rotation_matrix = torch.tensor(generate_rotation_matrix(n, seed), dtype=torch.float64)
    data = torch.tensor(data)
    zeros = torch.zeros((data.shape[0], n - data.shape[1]))
    rotated_data = torch.cat((data, zeros), dim=1) @ rotation_matrix
    if return_rot_mat:
        return rotated_data, rotation_matrix
    return rotated_data

# %% ../../nbs/library/datasets.ipynb 8
from .metrics import PullbackMetric
from .connections import LeviCivitaConnection
from .manifolds import RiemannianManifold
import sympy as sym
import numpy as np
import sympytorch
import warnings
from torch.func import vmap
import torch
from copy import deepcopy
import networkx as nx
from sklearn.neighbors import NearestNeighbors

class ToyManifold:
    def __init__(
        self,
        F, # parameterization of manifold, as a sympy matrix of size $N \times 1$
        variable_bounds, 
        num_points = 2000, # num points to sample
        seed = None,
        rotation_dimension:int = None, # if supplied, will randomly rotate the manifold into this dimension
        noise:float = 0, # if supplied, will add gaussian noise to the manifold with this standard deviation
    ):
        if seed is not None:
            np.random.seed(seed)
        self.F = F
        params = sorted(F.free_symbols, key=lambda s: s.name)
        self.param_list = [str(f) for f in params]
        self.intrinsic_dimension = len(self.param_list)
        self.variable_bounds = variable_bounds
        self.rotation_matrix = None
        self.X, self.intrinsic_coords = self.sample(num_points)
        self.X = torch.tensor(self.X, dtype=torch.float64)
        self.intrinsic_coords = torch.tensor(self.intrinsic_coords, dtype=torch.float64)
        # scale intrinsic coords back to 0,1
        self.intrinsic_coords = (self.intrinsic_coords - torch.min(self.intrinsic_coords))/(torch.max(self.intrinsic_coords)-torch.min(self.intrinsic_coords))
        self.X_ground_truth = self.X.clone()
        if rotation_dimension is not None:
            self.X, self.rotation_matrix = rotate_data(self.X, n = rotation_dimension, seed = seed, return_rot_mat = True)
        if noise:
            self.X = self.X + np.random.normal(0, noise, self.X.shape)
    
    def compute_metrics(self, compute_immersion = True):
        # compute metric information
        if compute_immersion:
            self.compute_immersion()
        self.metric = PullbackMetric(self.intrinsic_dimension, self.immersion)
        self.connection = LeviCivitaConnection(self.intrinsic_dimension, self.metric)
        self.manifold = RiemannianManifold(self.intrinsic_dimension, (1,1), metric = self.metric, connection = self.connection)
        # Compute basic manifold quantities
        try:
            self.ks = self.manifold.scalar_curvature(base_point = self.intrinsic_coords)
        except:
            warnings.warn("Something went awry during the scalar curvature computation.")

    def sample(
            self, num_points
    ):
        return rejection_sample_from_surface(
            F = self.F,
            n_points = num_points,
            bounds = self.variable_bounds,
            return_latent_vars=True,
        )
    
    def compute_immersion(self):
        # turns sympy extression into a pytorch function
        list_F = [item for sublist in self.F.tolist() for item in sublist]
        self.pytorch_function = sympytorch.SymPyModule(expressions = list_F)  
        # convert into a generic pytorch function that takes uniform samples in [0,1] and converts them to the right stuff.
        # the jacfwd functions from functorch go nuts with some negative inputs; hence the restriction.
        self.immersion = lambda x : self.pytorch_function(
            **{param: (x[i]*(self.variable_bounds[1] - self.variable_bounds[0]) + self.variable_bounds[0]) for i, param in enumerate(self.param_list)}
            )
    def decode(self, intrinsic_coords:torch.Tensor):
        intrinsic_coords = torch.tensor(intrinsic_coords)
        if len(intrinsic_coords.size()) == 1:
            intrinsic_coords = intrinsic_coords[None,:]
        return vmap(self.immersion)(intrinsic_coords)
    
    def encode(self, X:torch.Tensor):
        if len(X.size()) == 1:
            X = X[None,:]
        # Converts X to the intrinsic coords. Assumes that X is generated from self.sample
        return self.intrinsic_coords[torch.argmin(torch.cdist(self.X_ground_truth, X), axis=0)]
        
    def plot(self, labels = None, title=""):
        if labels is None: labels = self.ks
        plot_3d(
            self.X.detach().numpy(),
            self.ks.detach().numpy(),
            title = title
        )
        
    def pairwise_geodesic_via_djikstra(self, a, b, 
                                       ts, # ignored. For compatibility with other geodesic functions.
                                       k = 5):
        # Builds a nearest neighbor graph out of self.X_ground_truth. Then uses the djikstra algorithm to find the shortest path between a and b.
        # Assumes and and b are in the ground truth data.
        
        # get the indices of the closest points in X_ground_truth
        a_idx = int(torch.argmin(torch.linalg.norm(self.X_ground_truth - a, dim=1), dim=0))
        b_idx = int(torch.argmin(torch.linalg.norm(self.X_ground_truth - b, dim=1), dim=0))
        
        # For better results, we sample a whole bunch of points and add them to X_ground_truth
        X_extra_samples, _ = self.sample(50000)
        X_extra_samples = torch.tensor(X_extra_samples, dtype=torch.float64)
        X_combined = torch.cat([self.X_ground_truth, X_extra_samples], dim=0)
        
        # get k-nn
        nbrs = NearestNeighbors(n_neighbors=k+1, algorithm='auto').fit(X_combined)
        distances, indices = nbrs.kneighbors(X_combined)
        
        G = nx.Graph()
        # add nodes to G
        for i in range(len(X_combined)):
            G.add_node(i)
        # Add edges between each point and its k-nearest neighbors
        for i in range(len(X_combined)):
            for j in range(1, k+1):  # start from 1 to avoid self-loop (i.e., point itself)
                G.add_edge(i, indices[i][j], weight = torch.linalg.norm(X_combined[i] - X_combined[indices[i][j]]))
                G.add_edge(indices[i][j], i, weight = torch.linalg.norm(X_combined[i] - X_combined[indices[i][j]]))
        
        
        self.G = G
        # find the shortest path between a and b
        path = nx.shortest_path(G, a_idx, b_idx, weight = "weight")
        length = nx.shortest_path_length(G, a_idx, b_idx, weight = "weight")
        
        g = X_combined[path]
        return g, length
        
        
    def geodesics(self, start_points, end_points, ts):
        """
        Takes start, endpoint pairs in ambient space, and list of times. Returns geodesics and lengths.
        """
        # test if start and end points are tensors
        if isinstance(start_points, np.ndarray):
            start_points = torch.as_tensor(start_points)
        if isinstance(end_points, np.ndarray):
            end_points = torch.as_tensor(end_points)
        if isinstance(ts, np.ndarray):
            ts = torch.as_tensor(ts)
        
        # test if start and end points are among the previously sampled points
        # for each point, find the closest point in the sampled points. If it exceeds a threshold of 1e-3, then raise an error.
        distances_to_sampled_points = torch.cdist(torch.cat([start_points, end_points], dim=0), self.X)
        corresponding_idxs = torch.argmin(distances_to_sampled_points, dim=1)
        
        for i in range(len(start_points)):
            # closest_idx = torch.argmin(distances_to_sampled_points[i], dim=0)
            closest_value = distances_to_sampled_points[i][corresponding_idxs[i]]
            if closest_value > 1e-3:
                raise ValueError(f"Start and end points must be among the previously sampled points. Min dist to manifold is {closest_value}")
            
        # convert the start and end points to the corresponding points in the ground truth data
        start_points = self.X_ground_truth[corresponding_idxs[:len(start_points)]]
        end_points = self.X_ground_truth[corresponding_idxs[len(start_points):]]
            
        gs = []
        lengths = []
        for i in range(len(start_points)):
            if hasattr(self, "pairwise_geodesic"): # an analytic geodesic is available
                g, l = self.pairwise_geodesic(start_points[i], end_points[i], ts)
            else: # use the djikstra algorithm
                g, l = self.pairwise_geodesic_via_djikstra(start_points[i], end_points[i], ts)
            # convert g to double
            g = g.double()
            if self.rotation_matrix is not None:
                g = rotate_data(g, n = self.rotation_matrix.shape[0],  return_rot_mat = False, rotation_matrix = self.rotation_matrix)
            gs.append(g)
            lengths.append(l)
            
        # make conversion safe
        lengths = torch.tensor(lengths)
        gs = [g.cpu().detach() for g in gs]
        lengths = lengths.cpu().detach()
        return gs, lengths
    
    

# %% ../../nbs/library/datasets.ipynb 10
class Torus(ToyManifold):
    def __init__(self,num_points = 2000, R=2.0, r=1.0, rotation_dimension:int = None, noise:float = 0, seed = None):
        self.R, self.r = (R,r)
        theta = sym.Symbol('theta')
        phi = sym.Symbol('phi')
        F = sym.Matrix([(R + r*sym.cos(theta))*sym.cos(phi), (R + r*sym.cos(theta))*sym.sin(phi), r*sym.sin(theta)])
        super().__init__(F = F, variable_bounds = [0.0, 2*np.pi], num_points=num_points, rotation_dimension=rotation_dimension, noise=noise, seed = seed)
        self.compute_metrics()
    def scalar_curvature(self, X):
        theta = np.arcsin(X[:,2] / self.r)
        return 1/2*8*np.cos(theta)/(5 + np.cos(theta))

# %% ../../nbs/library/datasets.ipynb 22
class Saddle(ToyManifold):
    def __init__(self, num_points = 2000, a=1, b = 1, rotation_dimension:int = None, noise:float = 0, seed = None):
        # d = intrinsic_dim
        self.a, self.b = (a,b)
        x = sym.Symbol("x")
        y = sym.Symbol("y")
        F = sym.Matrix(
            [x,y,self.a*x**2 - self.b*y**2]
        )
        # vars = sp.symbols('x0:%d' % d)
        # F = sp.Matrix([*vars])
        # for i in range(d,d+1):
        #     F = F.row_insert(i, sp.Matrix([intensity*sum([(1)**j * vars[j]**2 for j in range(d)])]))
        #     print(F)
        super().__init__(F, variable_bounds = [-1, 1], num_points = num_points, rotation_dimension=rotation_dimension, noise=noise, seed = seed)
        self.compute_metrics(compute_immersion=False)
    def immersion(self, tensor_input):
        def pointwise_immersion(tensor_input):
            # scale input with bounds
            tensor_input = tensor_input*(self.variable_bounds[1] - self.variable_bounds[0]) + self.variable_bounds[0]
            x = tensor_input[0]
            y = tensor_input[1]
            return torch.vstack(
                [x, y, self.a*torch.square(x) - self.b*torch.square(y)]
            )
        if len(tensor_input.size()) == 1:
            return torch.squeeze(pointwise_immersion(tensor_input))
        else:
            return torch.squeeze(vmap(pointwise_immersion)(tensor_input))
    

# %% ../../nbs/library/datasets.ipynb 32
class Ellipsoid(ToyManifold):
    def __init__(self, num_points = 2000, a=3, b=2, c=1, rotation_dimension:int = None, noise:float = 0, seed = None):
        theta = sym.Symbol("theta")
        phi = sym.Symbol("phi")
        F = sym.Matrix(
            [a*sym.cos(theta)*sym.sin(phi),b*sym.sin(theta)*sym.sin(phi),c*sym.cos(phi)]
        )
        super().__init__(F, [0.0,2*np.pi], num_points = num_points, rotation_dimension = rotation_dimension, noise = noise, seed = seed)
        self.compute_metrics()

# %% ../../nbs/library/datasets.ipynb 39
class Sphere(ToyManifold):
    def __init__(self, num_points = 2000, r = 1, rotation_dimension:int = None, noise:float = 0, seed = None):
        self.r = r
        theta = sym.Symbol("theta")
        phi = sym.Symbol("phi")
        F = sym.Matrix(
            [r*sym.cos(theta)*sym.sin(phi),r*sym.sin(theta)*sym.sin(phi),r*sym.cos(phi)]
        )
        super().__init__(F, [0.0,2*np.pi], num_points = num_points, rotation_dimension = rotation_dimension, noise = noise, seed = seed)
        self.compute_metrics()
    def pairwise_geodesic(self, 
                 a, # Coordinates in ambient space
                 b, 
                 ts = None, # length of this is the number of times to sample along the geodesic
                 tolerance = 0.02
                 ):
        """
        Returns geodesic in ambient space between points a and b.
        """
        # if a and b are 2d, convert to 1d
        a = torch.squeeze(a)
        b = torch.squeeze(b)
        # get a linspace line between the two points
        if ts is None:
            ts = torch.linspace(0,1,20)
        g = torch.zeros(len(ts), 3)
        g[:,0] = torch.linspace(a[0], b[0], len(ts))
        g[:,1] = torch.linspace(a[1], b[1], len(ts))
        g[:,2] = torch.linspace(a[2], b[2], len(ts))
        # normalize each row in g to have unit length
        g = g / torch.linalg.norm(g, dim=1, keepdim=True)
        
        # compute length of geodesic
        angle = torch.linalg.norm(torch.cross(a, b, dim=-1))/self.r**2
        length = self.r * angle
        
        # cross = torch.cross(a, b, dim=-1)
        # agreement_with_cross = torch.func.vmap(lambda x: torch.dot(cross, x))(self.X)
        # great_circle_points = self.X[torch.abs(agreement_with_cross) < tolerance]
        # # restrict to points on the right side
        # agreement_with_sign = torch.func.vmap(lambda x: torch.dot(a + b, x))(great_circle_points)
        # great_circle_points = great_circle_points[agreement_with_sign > 0]
        return g, length
    def latent_geodesic(self,
                        a, b, 
                        ts = None, # Ignored. For compatibility with other geodesic functions. 
                        tolerance = 0.02):
        # if a and b are 1d, convert to 2d
        a = self.decode(a)
        b = self.decode(b)
        return self.encode(self.geodesic(a, b, tolerance = tolerance)[1])

# %% ../../nbs/library/datasets.ipynb 44
class Hemisphere(Sphere):
    def __init__(self, num_points = 2000, r = 1, threshold=0, rotation_dimension:int = None, noise:float = 0, seed = None):
        super().__init__(2*num_points, r, rotation_dimension=rotation_dimension, noise=noise, seed = seed)
        hemisphere_mask = self.X[:,2] > threshold
        self.X = self.X[hemisphere_mask]
        self.X_ground_truth = self.X_ground_truth[hemisphere_mask]

# %% ../../nbs/library/datasets.ipynb 48
class SwissRoll(ToyManifold):
    def __init__(self, num_points = 2000, r = 1, height = 21, delay = 1, num_spirals = 1.5, rotation_dimension:int = None, noise:float = 0, seed = None):
        self.r = r
        height = height 
        theta = sym.Symbol("theta")
        phi = sym.Symbol("phi")
        t = num_spirals * sp.pi * (delay + 2*theta) # Sklearn's parameterization of the swiss roll
        F = sym.Matrix(
            [r*sym.cos(t)*t,height*(phi), r*sym.sin(t)*t]
        )
        super().__init__(F, [0.0,1.0], num_points = num_points, rotation_dimension = rotation_dimension, noise = noise, seed = seed)
        self.compute_metrics()
        
    def intrinsic_distances(self):
        return torch.cdist(self.intrinsic_coords, self.intrinsic_coords)
        
    def pairwise_geodesic(self, 
                 a, # Coordinates in ambient space
                 b, 
                 ts,
                 tolerance = 0.02
                 ):
        """
        Returns geodesic in ambient space between points a and b.
        """
        # if a and b are 2d, convert to 1d
        a = torch.squeeze(a)
        b = torch.squeeze(b)
        # send to latent space
        a = self.encode(a)
        b = self.encode(b)
        # compute pairwise geodesics
        g, length = self.pairwise_latent_geodesic(a, b, ts = ts, tolerance = tolerance)
        return self.decode(g), length
        
    def pairwise_latent_geodesic(self,
                        a, b, # coordinates in latent space
                        ts, 
                        tolerance = 0.02):
        # geodesics on the swiss roll are just straight lines
        a = torch.squeeze(a)
        b = torch.squeeze(b)
        g = torch.zeros(len(ts), 2)
        g[:,0] = torch.linspace(a[0], b[0], len(ts))
        g[:,1] = torch.linspace(a[1], b[1], len(ts))
        length = torch.linalg.norm(a - b)
        return g, length

# %% ../../nbs/library/datasets.ipynb 61
import torch

class PointcloudDataset(torch.utils.data.Dataset):
    def __init__(self, pointcloud):
        self.pointcloud = torch.tensor(pointcloud, dtype=torch.float32)
        
    def __len__(self):
        return len(self.pointcloud)
    
    def __getitem__(self, idx):
        return self.pointcloud[idx]

class PointcloudWithDistancesDataset(torch.utils.data.Dataset):
    def __init__(self, pointcloud, distances, batch_size = 64):
        self.pointcloud = torch.tensor(pointcloud, dtype=torch.float32)
        self.distances = torch.tensor(distances, dtype=torch.float32)
        self.batch_size = batch_size

    def __len__(self):
        return len(self.pointcloud)
    
    def __getitem__(self, idx):
        batch_idxs = torch.randperm(len(self.pointcloud))[:self.batch_size]
        batch = {}
        batch['x'] = self.pointcloud[batch_idxs]
        batch['d'] = self.distances[batch_idxs][:,batch_idxs]
        return batch

# %% ../../nbs/library/datasets.ipynb 62
def dataloader_from_pointcloud_with_distances(pointcloud, distances, batch_size = 64):
    dataset = PointcloudWithDistancesDataset(pointcloud, distances, batch_size)
    dataloader = torch.utils.data.DataLoader(dataset, batch_size=None, shuffle=True)
    return dataloader

# %% ../../nbs/library/datasets.ipynb 63
def train_and_testloader_from_pointcloud_with_distances(
    pointcloud, distances, batch_size = 64, train_test_split = 0.8
):
    X = pointcloud
    D = distances
    split_idx = int(len(X)*train_test_split)
    X_train = X[:split_idx]
    X_test = X[split_idx:]
    D_train = D[:split_idx,:split_idx]
    D_test = D[split_idx:,split_idx:]
    trainloader = dataloader_from_pointcloud_with_distances(X_train, D_train, batch_size)
    testloader = dataloader_from_pointcloud_with_distances(X_test, D_test, batch_size)
    return trainloader, testloader

# %% ../../nbs/library/datasets.ipynb 65
import numpy as np
import plotly.graph_objects as go
import chart_studio
import chart_studio.plotly as py
import chart_studio.tools as tls

def plot_3d_vector_field(X, *vector_fields, names=None, arrow_length=0.5, upload_to_information_superhighway = False, username = "", api_key = "", filename = ""):
    """
    Create a 3D quiver plot with multiple vector fields.

    Args:
        X (list of tuples or arrays): Collection of points in 3D space.
        *vector_fields: Variable number of vector fields (lists of tuples or arrays).
        arrow_length (float): Scaling factor for arrow lengths.

    Returns:
        None
    """
    if names is None:
        names = [f"Vector Field {i}" for i in range(len(vector_fields))]
    
    fig = go.Figure()

    # Convert to NumPy array for vectorized operations
    X = np.array(X)

    # Generate a list of colors
    colors = ['blue', 'red', 'green', 'orange', 'purple', 'yellow', 'brown', 'pink', 'grey', 'cyan']
    if len(vector_fields) > len(colors):
        # Generate more colors if needed
        additional_colors = np.random.choice(colors, size=(len(vector_fields) - len(colors)))
        colors.extend(additional_colors)

    # Function to add arrows (vectors)
    def add_arrows(X, V, color, name):
        V = np.array(V) * arrow_length
        end_points = X + V
    
        # Arrows (cones)
        fig.add_trace(go.Cone(
            x=end_points[:, 0],
            y=end_points[:, 1],
            z=end_points[:, 2],
            u=V[:, 0],
            v=V[:, 1],
            w=V[:, 2],
            sizemode='absolute',
            sizeref=0.1,
            showscale=False,
            colorscale=[[0, color], [1, color]],
            cmin=0,
            cmax=1,
            name=name,
            legendgroup=name,
            showlegend=True  # Set to True to show in legend
        ))
    
        # Lines (arrow shafts)
        for start, end in zip(X, end_points):
            fig.add_trace(go.Scatter3d(
                x=[start[0], end[0]],
                y=[start[1], end[1]],
                z=[start[2], end[2]],
                mode='lines',
                line=dict(width=3, color=color),
                showlegend=False  # Set to False to avoid duplicate legend entries
            ))


    # Markers for points
    fig.add_trace(go.Scatter3d(
        x=X[:, 0],
        y=X[:, 1],
        z=X[:, 2],
        mode='markers',
        marker=dict(size=5, color='black'),
        name='Points',
        showlegend=False
    ))

    # Add arrows for each vector field
    for i, vector_field in enumerate(vector_fields):
        add_arrows(X, vector_field, colors[i % len(colors)], names[i])

    # Set axis labels
    fig.update_layout(scene=dict(
        xaxis_title='X',
        yaxis_title='Y',
        zaxis_title='Z'
    ), title=filename)

    # Show the plot
    fig.show()
    if upload_to_information_superhighway:
        url = py.plot(fig, filename = filename, auto_open=False)
        print("Your plot is now live at ",url)


# %% ../../nbs/library/datasets.ipynb 66
def sphere_with_normals(
    n_points
):
    X, ks = sphere(n_points)
    N = X
    return X, N

# %% ../../nbs/library/datasets.ipynb 68
import os
from fastcore.script import *
from .branch_datasets import Branch

@call_parse
def export_datasets(
    foldername:str,
    num_geodesics = 20,    
    num_points_per_geodesic = 3000,
    seed = 480851,
    get_geod=True,
):
    num_geodesics = 20
    num_points_per_geodesic = 3000
    get_geod=False
    """
    Saves all of the datasets above into npz files.
    """
    # check if the folder foldername exists. If not create it.
    if not os.path.exists(foldername):
        os.makedirs(foldername)
        
    np.random.seed(seed)

    dsets = {}
    for rot_dim in [None, 5, 10, 15, 50]:
        for noise in [0, 0.1, 0.3, 0.5, 0.7]:
            for mfd in [Hemisphere,Torus,Saddle,Ellipsoid]:
                dsets[f'{mfd.__name__}_{rot_dim}_{noise}'] = mfd(num_points = num_points_per_geodesic, rotation_dimension = rot_dim, noise = noise, seed = seed)


    # dsets = {
    #     'Nice Hemisphere' : Hemisphere(num_points = 3000, rotation_dimension = None, noise = 0, seed = seed), 
    #     'Neutral Hemisphere' : Hemisphere(num_points = 3000, rotation_dimension = 5, noise = 0.1, seed = seed), 
    #     'Evil Hemisphere' : Hemisphere(num_points = 3000, rotation_dimension = 15, noise = 0.3, seed = seed),

    #     'Nice Swiss Roll' : SwissRoll(num_points = 3000, r = 1, height = 21, delay = 1, num_spirals = 1.5, rotation_dimension=None, noise = 0, seed = seed), # sklearn parameters
    #     'Neutral Swiss Roll' : SwissRoll(num_points = 3000, r = 1, height = 21, delay = 1, num_spirals = 1.5, rotation_dimension=5, noise = 0.1, seed = seed), # sklearn parameters
    #     'Evil Swiss Roll' : SwissRoll(num_points = 3000, r = 1, height = 21, delay = 1, num_spirals = 1.5, rotation_dimension=15, noise = 0.3, seed = seed), # sklearn parameters
        
    #     'Nice Branch' : Branch(dimension = 3, num_samples = 3000, path_length = 3, max_branches = 3, seed = seed),
    #     'Neutral Branch' : Branch(dimension = 5, num_samples = 3000, path_length = 4, max_branches = 4, seed = seed),
    #     'Evil Branch' : Branch(dimension = 15, num_samples = 3000, path_length = 5, max_branches = 5, seed = seed),
        
    #     'Nice Torus' : Torus(num_points = 3000, R=2.0, r=1.0, rotation_dimension=None, noise=0, seed = seed),
    #     'Neutral Torus' : Torus(num_points = 3000, R=2.0, r=1.0, rotation_dimension=5, noise=0.1, seed = seed),
    #     'Evil Torus' : Torus(num_points = 3000, R=2.0, r=1.0, rotation_dimension=15, noise=0.3, seed = seed),
        
    #     'Nice Saddle' : Saddle(num_points = 3000, a=1, b = 1, rotation_dimension=None, noise=0, seed = seed),
    #     'Neutral Saddle' : Saddle(num_points = 3000, a=1, b = 1, rotation_dimension=5, noise=0.1, seed = seed),
    #     'Evil Saddle' : Saddle(num_points = 3000, a=1, b = 1, rotation_dimension=15, noise=0.3, seed = seed),
        
    #     'Nice Ellipsoid' : Ellipsoid(num_points = 3000, a=3, b=2, c=1, rotation_dimension=None, noise=0, seed = seed),
    #     'Neutral Ellipsoid' : Ellipsoid(num_points = 3000, a=3, b=2, c=1, rotation_dimension=5, noise=0.1, seed = seed),
    #     'Evil Ellipsoid' : Ellipsoid(num_points = 3000, a=3, b=2, c=1, rotation_dimension=15, noise=0.3, seed = seed),
    # }
    for dname, dset in zip(dsets.keys(), dsets.values()):
        print(f"Creating {dname}")
        # make dname filename safe
        dname = dname.replace(" ", "_")
        dname = dname.lower()
        # get geodesics
        # first sample points from dset.X
        X = dset.X
        X_ground_truth = dset.X_ground_truth
        
        # if these are torch tensors, convert to numpy
        if isinstance(X, torch.Tensor):
            X = X.detach().numpy()
            X_ground_truth = X_ground_truth.detach().numpy()
            
        endpoint_idxs = np.random.randint(0, dset.X.shape[0], size = num_geodesics*2)
        start_points = X[endpoint_idxs[:num_geodesics]]
        end_points = X[endpoint_idxs[num_geodesics:]]
        ts = np.linspace(0, 1, num_points_per_geodesic)
        if get_geod:
            print('getting geods')
            gs, ls = dset.geodesics(start_points, end_points, ts)
        
            # gs is a list; its contents may have different lengths, which will trip up np.savez
            # we pad the ends of the list with zeros to make them all the same length
            
            # convert to numpy arrays
            if isinstance(gs[0], torch.Tensor):
                gs = [g.detach().numpy() for g in gs]
                ls = ls.numpy()
                
        
            max_len = max([len(g) for g in gs])
            # pad the ends of the list with copies of the last element to make them all the same length, using np.vstack
            gs = [np.vstack([g[:-1], np.repeat(g[-1][None,:], max_len - len(g) + 1, axis = 0)]) for g in gs]
        else:
            print('no geod')
            gs, ls = None, None
        np.savez(
            os.path.join(foldername, f'{dname}.npz'), 
            X = X, 
            X_ground_truth = X_ground_truth,
            start_points = start_points, 
            end_points = end_points,
            geodesics = gs,
            geodesic_lengths = ls,
            
        )

# %% ../../nbs/library/datasets.ipynb 71
from .self_evaluating_datasets import SelfEvaluatingDataset, metric
from fastcore.all import *
import os.path
import numpy as np
from .criteria import geodesic_length_criterion, distance_to_geodesic_criterion
from .utils import plot_3d_with_geodesics

class GeodesicToyChest(SelfEvaluatingDataset):
    def __init__(self,
                 saved_directory:str, # loads the saved npz files from this directory
                 manifolds = ['Nice Hemisphere', 'Nice Swiss Roll', 'Nice Torus', 'Nice Saddle', 'Nice Branch', 'Nice Ellipsoid'],
                ):
        store_attr()
        datalist = []
        names = manifolds

        for name in names:
            file_name = name.replace(" ", "_").lower() + '.npz'
            x = np.load(os.path.join(saved_directory, file_name))
            datalist.append(
                {
                    'X' : x['X'], 
                    'X_ground_truth' : x['X_ground_truth'],
                    'start_points' : x['start_points'], 
                    'end_points' : x['end_points'],
                    'geodesics' : x['geodesics'],
                    'geodesic_lengths' : x['geodesic_lengths'],
                }
            )
        super().__init__(datalist, names, ['geodesic points', 'geodesic lengths'])
    def get_item(self, idx):
        return torch.tensor(self.DS[idx].obj['X'], dtype=torch.float32), torch.tensor(self.DS[idx].obj['start_points'], dtype=torch.float32), torch.tensor(self.DS[idx].obj['end_points'], dtype=torch.float32)
    def get_truth(self, result_name, idx):
        if result_name == 'geodesic points':
            return self.DS[idx].obj['geodesics']
        elif result_name == 'geodesic lengths':
            return self.DS[idx].obj['geodesic_lengths']

    def plot_geodesics(self, name, geodesic_idx=None):
        if name not in self.names:
            print("Not among my manifolds, which are",self.names)
        idx = self.names.index(name)
        a = self.DS[idx]
        X = a.obj['X']
        if geodesic_idx is not None:
            gs = a.results['geodesic points']['off-manifold-pullback'][geodesic_idx]
            true_gs = a.results['geodesic points']['ground truth'][geodesic_idx]
        else:
            gs = a.results['geodesic points']['off-manifold-pullback']
            true_gs = a.results['geodesic points']['ground truth']
        plot_3d_with_geodesics(X, gs, true_gs)

    def compute_metrics_for_manifold(self, name):
        if name not in self.names:
            print("Not among my manifolds, which are",self.names)
        idx = self.names.index(name)
        # use compute_metrics with custom labels, which are just for the dataset
        single_manifold_table = self.compute_metrics(labels = self.DS[idx].results)
        print(single_manifold_table)
        return single_manifold_table
            
        
    
    @metric
    def length_mse(self, a, b, result_name):
        if result_name == "geodesic lengths":
            return float(geodesic_length_criterion(a, b))
        else:
            return -1
    @metric
    def distance_to_geodesic(self, a, b, result_name):
        if result_name == "geodesic points":
            
            return float(distance_to_geodesic_criterion(a, b))
        else:
            return -1
        
        
