{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "\"\"\"\n",
    "DiffGeo file containing everything related to the pullback metric\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "import geomstats.backend as gs\n",
    "from torch.autograd.functional import jacobian\n",
    "from functorch import jacfwd\n",
    "\n",
    "os.environ[\"GEOMSTATS_BACKEND\"] = \"pytorch\"\n",
    "\n",
    "import torch\n",
    "\n",
    "from autometric.util import batch_jacobian\n",
    "\n",
    "from geomstats.geometry.riemannian_metric import RiemannianMetric\n",
    "\n",
    "\n",
    "class PullbackMetric(RiemannianMetric):\n",
    "    def __init__(self, dim, immersion, shape=None, signature=None, default_point_type=None):\n",
    "        super().__init__(dim, shape=shape, signature=signature, default_point_type=default_point_type)\n",
    "        self.immersion = immersion\n",
    "\n",
    "    def normalize(self, v, point):\n",
    "        \"\"\"\n",
    "        normalize vector at point\n",
    "        :param v: vector\n",
    "        :param point: point\n",
    "        :return: normal vector\n",
    "        \"\"\"\n",
    "\n",
    "        return v / self.norm(v, point)\n",
    "\n",
    "    def metric_matrix_derivative(self, base_point=None):\n",
    "        \"\"\"\n",
    "        Compute derivative of the inner prod matrix at base point.\n",
    "\n",
    "        :param base_point : Base point\n",
    "        :returns: matrix derivative\n",
    "        \"\"\"\n",
    "\n",
    "        metric_derivative = batch_jacobian(self.metric_matrix, base_point)\n",
    "\n",
    "        return metric_derivative\n",
    "\n",
    "    def norm(self, vector, base_point=None, matrix=None):\n",
    "        \"\"\"\n",
    "        Norm function that doesn't generate a new matrix because it already exists\n",
    "        :param matrix: matrix for norm\n",
    "        :param vector: vector which we want to calculate the norm of\n",
    "        :return: norm\n",
    "        \"\"\"\n",
    "        if matrix is None:\n",
    "            return super().norm(vector, base_point)\n",
    "        else:\n",
    "            if vector.dim() > 1:\n",
    "                result = torch.einsum(\"ijk,kl->ijl\", matrix, vector)\n",
    "                result = torch.einsum(\"mn,imn->in\", vector, result)\n",
    "                result = torch.sqrt(result)\n",
    "\n",
    "                return result\n",
    "            else:\n",
    "                return torch.sqrt(vector @ matrix @ vector)\n",
    "\n",
    "    def inner_product(self, tangent_vec_a, tangent_vec_b, base_point=None, matrix=None):\n",
    "        \"\"\"\n",
    "        Inner product if matrix is already calculated\n",
    "        :param base_point: the basepoint under consideration\n",
    "        :param matrix: metric\n",
    "        :param tangent_vec_a: first vector\n",
    "        :param tangent_vec_b: second vector\n",
    "        :return: inner product\n",
    "        \"\"\"\n",
    "\n",
    "        if matrix is None:\n",
    "            return super().inner_product(tangent_vec_a, tangent_vec_b, base_point)\n",
    "        else:\n",
    "            prod = torch.einsum(\"...i,...ij,j->...\", tangent_vec_a, matrix, tangent_vec_b)\n",
    "\n",
    "            return prod\n",
    "\n",
    "    def cometric_matrix(self, base_point=None, metric_matrix=None):\n",
    "        \"\"\"\n",
    "        Inner co-product matrix at the cotangent space at a base point.\n",
    "\n",
    "        :param base_point: the base point\n",
    "        :param metric_matrix: the matrix to be inverted. If passed not computed twice\n",
    "        :return : inverse of the metric matrix\n",
    "        \"\"\"\n",
    "\n",
    "        if metric_matrix is None:\n",
    "            metric_matrix = self.metric_matrix(base_point)\n",
    "\n",
    "        # invert the batch of matrices\n",
    "        inv_ex = torch.linalg.inv_ex(metric_matrix)\n",
    "        cometric_matrix = inv_ex.inverse\n",
    "\n",
    "        # remove the non-invertible matrices\n",
    "        # projector = torch.ones_like(cometric_matrix)\n",
    "        # problematics = inv_ex.info != 0\n",
    "        # projector[problematics] = torch.zeros((2, 2), device=device)\n",
    "\n",
    "        cometric_matrix = torch.nan_to_num(cometric_matrix, 0, 0, 0)  # * projector\n",
    "\n",
    "        # if torch.any(problematics):\n",
    "        #    print(f\"{Color.RED}[WARNING] metric not invertible at points {base_point[problematics].data}{Color.NC}\")\n",
    "\n",
    "        return cometric_matrix\n",
    "\n",
    "    def metric_matrix(self, base_point=None, **joblib_kwargs):\n",
    "        \"\"\"\n",
    "        Calculates pullback of euclidian metric under f at point\n",
    "        :param base_point: point at which we want to calculate the metric\n",
    "        :return: pullback of euclidian metric under f at point\n",
    "        \"\"\"\n",
    "\n",
    "        #print(base_point.shape)\n",
    "        #print(self.immersion(base_point).shape)\n",
    "\n",
    "        J = batch_jacobian(self.immersion, base_point)\n",
    "\n",
    "        base_point = torch.squeeze(base_point)\n",
    "\n",
    "        if base_point.dim() == 1:\n",
    "            J = torch.squeeze(J)\n",
    "            metric = J.T @ J\n",
    "        else:\n",
    "            J = torch.squeeze(J)\n",
    "            metric = torch.matmul(torch.transpose(J, 1, 2), J)\n",
    "\n",
    "        return metric\n",
    "\n",
    "    def christoffels(self, base_point):\n",
    "        \"\"\"\n",
    "        Compute Christoffel symbols of the Levi-Civita connection.\n",
    "\n",
    "        :param base_point : the base point\n",
    "        :param cometric_matrix: the cometric matrix, so it doesn't have to be calculated multiple times\n",
    "        :param metric_matrix_derivative: derivative of cometric matrix so just computed once\n",
    "        :returns : Christoffels\n",
    "        \"\"\"\n",
    "\n",
    "        cometric_matrix = self.cometric_matrix(base_point)\n",
    "        metric_matrix_derivative = self.metric_matrix_derivative(base_point)\n",
    "\n",
    "        term_1 = gs.einsum(\n",
    "            # \"...lk,...jli->...kij\", cometric_matrix, metric_matrix_derivative\n",
    "            \"...kl,...jli->...kij\", cometric_matrix, metric_matrix_derivative\n",
    "        )\n",
    "        term_2 = gs.einsum(\n",
    "            # \"...lk,...ilj->...kij\", cometric_matrix, metric_matrix_derivative  # lij? no!\n",
    "            \"...kl,...ilj->...kij\", cometric_matrix, metric_matrix_derivative\n",
    "        )\n",
    "        term_3 = -gs.einsum(\n",
    "            # \"...lk,...ijl->...kij\", cometric_matrix, metric_matrix_derivative\n",
    "            \"...kl,...ijl->...kij\", cometric_matrix, metric_matrix_derivative\n",
    "        )\n",
    "\n",
    "        christoffels = 0.5 * (term_1 + term_2 + term_3)\n",
    "\n",
    "        return christoffels\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
