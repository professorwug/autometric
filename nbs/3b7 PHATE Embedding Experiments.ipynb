{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_150906/1668703105.py:25: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  style.use('seaborn-poster') #sets the size of the charts\n",
      "INFO: Using pytorch backend\n"
     ]
    }
   ],
   "source": [
    "#|default_exp n3b7_phate_embedding_experiments\n",
    "#|export\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# datasets\n",
    "from diffusion_curvature.datasets import sphere, torus\n",
    "from sympy import im\n",
    "from autometric.n0d2_datasets import make_swiss_roll, generate_sine_wave_dataset\n",
    "from autometric.n0u1_visualization import plot_jacobian, plot_jacobian_multi\n",
    "from autometric.n0u2_jacobian import compute_jacobian_function\n",
    "\n",
    "import os\n",
    "os.environ[\"GEOMSTATS_BACKEND\"] = \"pytorch\"\n",
    "\n",
    "# models\n",
    "import torch\n",
    "from autometric.autoencoders import DerrickTheAutoencoder\n",
    "from diffusion_curvature.utils import plot_3d\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# \n",
    "import matplotlib.style as style\n",
    "style.use('seaborn-poster') #sets the size of the charts\n",
    "style.use('ggplot')\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "import phate\n",
    "from autometric.geometry import visualize_encoder_pullback_metrics\n",
    "from autometric.geometry import visualize_encoder_pullback_metrics_in_ambient_space\n",
    "from autometric.autoencoders import DistanceMatchingAutoencoder\n",
    "from autometric.autoencoders import CoordinatewiseDistanceMatchingAutoencoder\n",
    "from autometric.datasets import train_and_testloader_from_pointcloud_with_distances\n",
    "from autometric.datasets import train_and_testloader_from_pointcloud_phate_coords\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "import pathlib\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def run_PHATE_embedding_experiment(\n",
    "        datasetname,\n",
    "        phate_decay = 40,\n",
    "        n_neighbors = 15,\n",
    "        phate_gamma = 1,\n",
    "        phate_knn = 15,\n",
    "        distance_weight = 1,\n",
    "        reconstruction_weight = 1,\n",
    "        dist_loss_fn = 'coordinatewise',\n",
    "        savepath = '../data',\n",
    "        max_epochs = 50,\n",
    "        plot=False\n",
    "    ):\n",
    "    pathlib.Path(savepath).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if datasetname == 'swiss_roll':\n",
    "        scale = 0.2\n",
    "    elif datasetname == 'wavy_sheet':\n",
    "        scale = 0.5\n",
    "    elif datasetname == 'sphere':\n",
    "        scale = 0.2\n",
    "    elif datasetname == 'torus':\n",
    "        scale = 0.5\n",
    "    else:\n",
    "        raise ValueError(f'Unknown dataset name: {datasetname}')\n",
    "\n",
    "    if os.path.exists(f\"{savepath}/{datasetname}.npy\"):\n",
    "        X = np.load(f\"{savepath}/{datasetname}.npy\")\n",
    "        print(\"Loaded dataset from disk\")\n",
    "    else:\n",
    "        if datasetname == 'swiss_roll':\n",
    "            Xs, thetas = make_swiss_roll(turns=2, a=0.1, base_delta_theta=0.1 * 2 * np.pi, theta=1.5 * np.pi, noise=0.)\n",
    "            ambient_noise = np.random.normal(0, 0.05, size=Xs.shape)\n",
    "            Xs += ambient_noise\n",
    "        elif datasetname == 'wavy_sheet':\n",
    "            Xs = generate_sine_wave_dataset(num_points=2000, amplitude=2, frequencies=(1, 1))\n",
    "            ambient_noise = np.random.normal(0, 0.05, size=Xs.shape)\n",
    "            Xs += ambient_noise\n",
    "        elif datasetname == 'sphere':\n",
    "            Xs, N = sphere(n=2000, noise=0.05)\n",
    "        elif datasetname == 'torus':\n",
    "            Xs, N = torus(n=2000, noise=0.05)\n",
    "        else:\n",
    "            raise ValueError(f'Unknown dataset name: {datasetname}')\n",
    "        X = Xs\n",
    "        np.save(f\"{savepath}/{datasetname}.npy\", X)\n",
    "\n",
    "    if os.path.exists(f\"{savepath}/phate_{datasetname}_coords.npy\") and os.path.exists(f\"{savepath}/phate_{datasetname}_D.npy\"):\n",
    "        phate_coords = np.load(f\"{savepath}/phate_{datasetname}_coords.npy\")\n",
    "        phate_D = np.load(f\"{savepath}/phate_{datasetname}_D.npy\")\n",
    "        print(\"Loaded PHATE embedding from disk\")\n",
    "    else:\n",
    "        print(f\"Computing PHATE with {phate_decay=} and {n_neighbors=}\")\n",
    "        phate_op = phate.PHATE(gamma=phate_gamma, knn=phate_knn, random_state=42) #n_components = 2, decay=phate_decay, knn=self.n_neighbors\n",
    "        phate_coords = phate_op.fit_transform(X)\n",
    "        phate.plot.scatter2d(phate_coords)\n",
    "        phate_coordst = torch.tensor(phate_coords)\n",
    "        phate_D = torch.cdist(phate_coordst, phate_coordst).cpu().detach().numpy()\n",
    "        np.save(f\"{savepath}/phate_{datasetname}_coords.npy\", phate_coords)\n",
    "        np.save(f\"{savepath}/phate_{datasetname}_D.npy\", phate_D)\n",
    "\n",
    "    if dist_loss_fn == 'coordinatewise':\n",
    "        # Create dataloaders\n",
    "        trainloader, testloader = train_and_testloader_from_pointcloud_phate_coords(\n",
    "            X, # <---- Pointcloud\n",
    "            phate_coords, # <---- Coordinates to match\n",
    "            batch_size=64)\n",
    "        train_sample = next(iter(trainloader))\n",
    "        # Initialize model and trainer\n",
    "        model = CoordinatewiseDistanceMatchingAutoencoder(\n",
    "            input_dim = train_sample['x'].shape[1],\n",
    "            intrinsic_dim = 2,\n",
    "            reconstruction_weight = reconstruction_weight,\n",
    "            distance_weight = distance_weight,\n",
    "            )\n",
    "    elif dist_loss_fn == 'all_coordinates':\n",
    "        # Create dataloaders\n",
    "        trainloader, testloader = train_and_testloader_from_pointcloud_with_distances(\n",
    "            X, # <---- Pointcloud\n",
    "            phate_D, # <---- Distance matrix to match\n",
    "            batch_size=64)\n",
    "        train_sample = next(iter(trainloader))\n",
    "\n",
    "        # Initialize model and trainer\n",
    "        model = DistanceMatchingAutoencoder(\n",
    "            input_dim = train_sample['x'].shape[1],\n",
    "            intrinsic_dim = 2,\n",
    "            reconstruction_weight = reconstruction_weight,\n",
    "            distance_weight = distance_weight,\n",
    "            )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown distance loss function {dist_loss_fn}\")\n",
    "\n",
    "    early_stopping = EarlyStopping('val_loss', patience=500)\n",
    "    trainer = Trainer(\n",
    "        max_epochs=max_epochs, \n",
    "        accelerator='cuda',\n",
    "        callbacks=[early_stopping],\n",
    "        use_distributed_sampler=False,\n",
    "        log_every_n_steps=50,\n",
    "        )\n",
    "    model_filename = f\"{datasetname}_{dist_loss_fn}_{reconstruction_weight}_{distance_weight}_encoder.pt\"\n",
    "\n",
    "    if os.path.exists(f'{savepath}/{model_filename}'):\n",
    "        model.load_state_dict(torch.load(f'{savepath}/{model_filename}'))\n",
    "    else:\n",
    "        trainer.fit(\n",
    "            model=model,\n",
    "            train_dataloaders=trainloader,\n",
    "            val_dataloaders=testloader,\n",
    "        )\n",
    "        torch.save(model.state_dict(), f'{savepath}/{model_filename}')\n",
    "    if plot:\n",
    "        visualize_encoder_pullback_metrics(model, trainloader, title = f\"PHATE Embedding of {datasetname}\")\n",
    "\n",
    "        visualize_encoder_pullback_metrics_in_ambient_space(model, trainloader, title = f\"PHATE Embedding of {datasetname}\")\n",
    "\n",
    "        X_tensor = torch.from_numpy(X).float()\n",
    "        jac = compute_jacobian_function(model.encoder, X_tensor)\n",
    "        U, S, V = torch.linalg.svd(jac, full_matrices=False)\n",
    "        X_enc = model.encoder(X_tensor)\n",
    "\n",
    "        js = np.random.choice(X.shape[0], size=100)\n",
    "        plot_jacobian_multi(X_tensor, X_enc, U, V, S, jac, js, scale1=scale)\n",
    "\n",
    "        enc = model.encoder(X_tensor)\n",
    "        ground_truth_distances = torch.from_numpy(phate_D).float()\n",
    "        phate_coords = torch.from_numpy(phate_coords).float()\n",
    "        if dist_loss_fn == 'coordinatewise':\n",
    "            dist_l = model.distance_loss(enc, phate_coords)\n",
    "        elif dist_loss_fn == 'all_coordinates':\n",
    "            dist_l = model.distance_loss(enc, ground_truth_distances)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown distance loss function {dist_loss_fn}\")\n",
    "        x_hat = model.decoder(enc)\n",
    "        from torch import nn\n",
    "        reconstr_l = nn.MSELoss()(x_hat, X_tensor)\n",
    "        print(f\"Distance loss: {dist_l.item():.3f}, Reconstruction loss: {reconstr_l.item():.3f}\")\n",
    "\n",
    "        x_embedded = enc\n",
    "        embedding_distances = torch.cdist(x_embedded, x_embedded)\n",
    "        prepared_embedded = (embedding_distances)        \n",
    "        prepared_truth = (ground_truth_distances)\n",
    "        dist_l_new = nn.MSELoss()(prepared_embedded, prepared_truth)\n",
    "        print(dist_l_new.item())\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "        ax1.scatter(x_embedded.detach().numpy()[:, 0], x_embedded.detach().numpy()[:, 1], c=phate_coords.detach().numpy()[:, 0])\n",
    "        ax1.set_xlabel('x_embedded[:,0]')\n",
    "        ax1.set_ylabel('x_embedded[:,1]')\n",
    "        ax1.set_title('x_embedded colored by phate_coords[:,0]')\n",
    "\n",
    "        ax2.scatter(x_embedded.detach().numpy()[:, 0], x_embedded.detach().numpy()[:, 1], c=phate_coords.detach().numpy()[:, 1])\n",
    "        ax2.set_xlabel('x_embedded[:,0]')\n",
    "        ax2.set_ylabel('x_embedded[:,1]')\n",
    "        ax2.set_title('x_embedded colored by phate_coords[:,1]')\n",
    "\n",
    "        plt.suptitle(f'{datasetname}: Comparison of x_embedded and phate_coords, distance loss: {dist_l.item():.2e}, distance MSE: {dist_l_new.item():.2e}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset from disk\n",
      "Loaded PHATE embedding from disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/autometric/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_env ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "datasetname = \"swiss_roll\"\n",
    "distance_weight = 1\n",
    "reconstruction_weight = 1\n",
    "dist_loss_fn = 'coordinatewise'\n",
    "# dist_loss_fn = 'all_coordinates'\n",
    "\n",
    "run_PHATE_embedding_experiment(\n",
    "    datasetname,\n",
    "    distance_weight = distance_weight,\n",
    "    reconstruction_weight = reconstruction_weight,\n",
    "    dist_loss_fn = dist_loss_fn,\n",
    "    savepath = '../test',\n",
    "    max_epochs = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset from disk\n",
      "Loaded PHATE embedding from disk\n"
     ]
    }
   ],
   "source": [
    "datasetname = \"swiss_roll\"\n",
    "distance_weight = 1\n",
    "reconstruction_weight = 1\n",
    "# dist_loss_fn = 'coordinatewise'\n",
    "dist_loss_fn = 'all_coordinates'\n",
    "\n",
    "run_PHATE_embedding_experiment(\n",
    "    datasetname,\n",
    "    distance_weight = distance_weight,\n",
    "    reconstruction_weight = reconstruction_weight,\n",
    "    dist_loss_fn = dist_loss_fn,\n",
    "    savepath = '../test',\n",
    "    max_epochs = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
