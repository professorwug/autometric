{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#|default_exp self_evaluating_datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import deepdish\n",
    "\n",
    "import os\n",
    "os.environ[\"GEOMSTATS_BACKEND\"] = \"pytorch\"\n",
    "\n",
    "# models\n",
    "import torch\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from fastcore.all import *\n",
    "import inspect\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def metric(func):\n",
    "    setattr(func, 'tag', 'metric')\n",
    "    return func\n",
    "\n",
    "class Wrapper:\n",
    "    def __init__(self, obj, **kwargs):\n",
    "        self.obj = obj\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "class SelfEvaluatingDataset():\n",
    "    def __init__(self,\n",
    "                 datalist:List, # list of objects to be evaluated in the dataset. Usually includes multiple examples, e.g. a torus, sphere, saddle; multiple images, multiple validation datasets.\n",
    "                 names:List, # names of the datasets in datalist.\n",
    "                 result_names:List,\n",
    "                ):\n",
    "        store_attr()\n",
    "\n",
    "        self.DS = [ # list of datasets\n",
    "            Wrapper(obj, results={rn:{} for rn in result_names}, name=name) for obj, name in zip(datalist, names)\n",
    "        ]\n",
    "        self.idx = -1\n",
    "        for i in range(self.__len__()):\n",
    "            # aggregate ground truth values\n",
    "            for rn in self.result_names:\n",
    "                self._store_truth(rn, i)\n",
    "\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.DS)\n",
    "    \n",
    "    def preprocess(self, unprocessed_data_object):\n",
    "        return unprocessed_data_object # override\n",
    "    \n",
    "    def get_item(self, idx):\n",
    "        return self.DS[idx]\n",
    "\n",
    "    def __next__(self):\n",
    "        self.idx += 1\n",
    "        if self.idx >= self.__len__():\n",
    "            raise StopIteration\n",
    "        result = self.get_item(self.idx)\n",
    "        return result\n",
    "\n",
    "    def update(self,\n",
    "               result,\n",
    "               idx = None,\n",
    "               result_name = 'default',\n",
    "               method_name='computed',\n",
    "               ):\n",
    "        \"\"\"\n",
    "        Store the result of the curvature computation by passing the computed curvature of the center (first) point.\n",
    "        \"\"\"\n",
    "        if idx is None: idx = self.idx\n",
    "        self.DS[idx].results[result_name][method_name] = result\n",
    "\n",
    "    def get_truth(self, result_name, idx):\n",
    "        \"\"\"Compute the ground truth for each of your targets, and assign to a method. Usually this involves accessing some attribute of the input data and calling the update function\"\"\"\n",
    "        truth = None\n",
    "        return truth\n",
    "\n",
    "    \n",
    "    def _store_truth(self, result_name, idx):\n",
    "        truth = self.get_truth(result_name, idx)\n",
    "        self.update(\n",
    "            truth, idx, method_name = \"ground truth\", result_name=result_name\n",
    "        )\n",
    "\n",
    "\n",
    "    def compute_metrics(self, filter = None):\n",
    "        self._aggregate_labels()\n",
    "        metrics = self._get_metrics()\n",
    "        self.metric_tables = {rn : {} for rn in self.result_names}\n",
    "        for rn in self.result_names:\n",
    "            for metric in metrics:\n",
    "                self.metric_tables[rn][metric.__name__] = {}\n",
    "                for method_name in self.method_names:\n",
    "                    self.metric_tables[rn][metric.__name__][method_name] = self.compute(metric=metric, method_name=method_name, result_name=rn, filter = None)\n",
    "            self.metric_tables[rn] = pd.DataFrame(self.metric_tables[rn])\n",
    "            \n",
    "    def compute(self, metric, result_name, method_name):\n",
    "        # Overwrite this class with your logic. It implements the computation of a single metric for a single method\n",
    "        return metric(self.labels[result_name][method_name], self.labels[result_name]['ground truth'])\n",
    "    \n",
    "\n",
    "    def _aggregate_labels(self):\n",
    "        # returns a dictionary whose keys are method names, paired with a list of each of the results given by the metrics.\n",
    "        # Just a more convenient data format for comparing method outputs.\n",
    "        self.method_names = list(self.DS[0].results[self.result_names[0]].keys())\n",
    "        self.labels = {}\n",
    "        for rn in self.result_names:\n",
    "            self.labels[rn] = {}\n",
    "            for m in self.method_names:\n",
    "                self.labels[rn][m] = [self.DS[i].results[rn][m] for i in range(self.__len__())]\n",
    "\n",
    "\n",
    "    def plot(self, title = None):\n",
    "        if title is None: title = f\"In dimension {self.dimension}\"\n",
    "        # for each computed method on this dataset, we plot the histogram of saddles vs spheres\n",
    "        self._aggregate_labels()\n",
    "        # get the idxs for each type of dataset\n",
    "        dataset_names = [self.DS.data_vars[i].attrs['name'] for i in range(len(self.DS))]\n",
    "        unique_names = list(set(dataset_names))\n",
    "        idxs_by_name = {n: [i for i, name in enumerate(dataset_names) if name == n] for n in unique_names}        \n",
    "        for m in self.method_names: \n",
    "            if m != 'ks' and m != 'name':\n",
    "                for dname in unique_names:\n",
    "                    plt.hist(self.labels[m][idxs_by_name[dname]], bins=50, label = dname, edgecolor='none', linewidth=5)\n",
    "                plt.legend()\n",
    "                plt.xlabel(m)\n",
    "                plt.title(title)\n",
    "                plt.show()\n",
    "\n",
    "    def table(self, filter=None):\n",
    "        self.compute_metrics(filter=filter)\n",
    "        for k in self.metric_tables.keys():\n",
    "            print(k)\n",
    "            print(self.metric_tables[k])\n",
    "        return self.metric_tables\n",
    "\n",
    "    def _get_metrics(self):\n",
    "        tagged_functions = []\n",
    "        for name, member in inspect.getmembers(self, predicate=inspect.ismethod):\n",
    "            if hasattr(member, 'tag') and getattr(member, 'tag') == 'metric':\n",
    "                tagged_functions.append(member)\n",
    "        return tagged_functions\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "Red\n"
     ]
    }
   ],
   "source": [
    "dls = [3,1,4,1,5,9,2,6,5]\n",
    "class Wrapper:\n",
    "    def __init__(self, obj, **kwargs):\n",
    "        self.obj = obj\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "# Example usage with a list of strings (but can be any objects)\n",
    "original_objects = [\"Apple\", \"Banana\"]\n",
    "\n",
    "wrapped_objects = [\n",
    "    Wrapper(obj, color=\"Red\", weight=150) for obj in original_objects\n",
    "]\n",
    "\n",
    "# Accessing attributes\n",
    "print(wrapped_objects[0].obj)  # Output: Apple\n",
    "print(wrapped_objects[0].color)  # Output: Red\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Red'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapped_objects[1].__dict__['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
